{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639c35f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ldap-users-2/dwipraseetyo-a/Project/Qwen2.5-Omni\n"
     ]
    }
   ],
   "source": [
    "%cd /home/is/dwipraseetyo-a/NAS_HAI/Project/Qwen2.5-Omni\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import os, librosa, random, pickle, pydicom, requests, torch, re\n",
    "from pydicom.datadict import keyword_for_tag\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import commons, const_variable\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f82bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cdfae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You are an advanced medical assistant AI specialized in analyzing and diagnosing clinical conditions, capable of perceiving auditory and visual inputs. \n",
    "You can interpret and reason over various medical inputs, including auditory inputs, visual inputs, and patient symptoms, individually or in combination, depending on what is provided. \n",
    "Your task is to analyze the given input, explain your reasoning, and give a possible diagnosis. \n",
    "Always respond in the following format:\n",
    "\n",
    "## ‚ö†Ô∏è Points to Review and Disclaimer\n",
    "<If no auditory or visual input is provided>\n",
    "\n",
    "## üß† Overview\n",
    "<Diagnosis sentence>\n",
    "\n",
    "## üìã Observations\n",
    "**Chest X-ray:**\n",
    "<Your explanation based on the relevant visual input>\"\n",
    "\n",
    "**Symptoms:**\n",
    "<Your explanation based on the input symptoms>\"\n",
    "\n",
    "**Audio:**\n",
    "<Your explanation based on the input audio>\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729ecd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1648674/520988073.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/gpt4_symptoms.csv.{split}\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "/tmp/ipykernel_1648674/520988073.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.{split}\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "Processing train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2151/2151 [00:00<00:00, 5277.76it/s]\n",
      "/tmp/ipykernel_1648674/520988073.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/gpt4_symptoms.csv.{split}\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "/tmp/ipykernel_1648674/520988073.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.{split}\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "Processing dev: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 269/269 [00:00<00:00, 9237.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'dev']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.{split}\")\n",
    "    df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/gpt4_symptoms.csv.{split}\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) ) \n",
    "    df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.{split}\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
    "    df = pd.merge(df, df_llm_symptoms, on='barcode', how='left')\n",
    "    df = pd.merge(df, df_llm_images, on='path_file_image', how='left')\n",
    "    df = df.rename(columns={'coughdur': 'cough_duration', 'ngtsweats': 'night_sweets', 'weightloss': 'weight_loss', 'body_wt': 'body_weight'})\n",
    "\n",
    "    instruct_array = []\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split}\", total=len(df)):\n",
    "        row_dict = now_row._asdict()\n",
    "        now_audiopath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_audio\n",
    "        now_imgaepath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_image\n",
    "\n",
    "        for i in range(6):\n",
    "            array_df = [None, None]\n",
    "            question, modalities = commons.unique_modalities_generator(const_variable.prompt_templates)\n",
    "            question += \". \"\n",
    "            answer = commons.generate_tb_response(modalities, now_row.llm_analyze_symptoms, now_row.llm_analyze_image, positive=(now_row.ground_truth_tb == 1))\n",
    "            \n",
    "            if now_row.path_file_audio == 'Unknown':\n",
    "                modalities = [m for m in modalities if m != \"audio\"]\n",
    "\n",
    "            array_df = [None, None]\n",
    "            if \"symptoms\" in modalities:\n",
    "                row_dict = now_row._asdict()\n",
    "                selected_feats = random.sample(const_variable.columns_soundfeat, k=random.randint(3, len(const_variable.columns_soundfeat)))\n",
    "                symptom_descriptions = \", \".join(\n",
    "                    f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "                    for feat in selected_feats\n",
    "                    if row_dict.get(feat) != \"Unknown\"\n",
    "                )\n",
    "                if symptom_descriptions:\n",
    "                    question += f\" Also, the patient presents with: {symptom_descriptions}.\"\n",
    "\n",
    "            if \"audio\" in modalities:\n",
    "                array_df[0] = now_audiopath\n",
    "\n",
    "            if \"xray\" in modalities:\n",
    "                array_df[1] = now_imgaepath\n",
    "                xray_descriptions = \", \".join(\n",
    "                    f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "                    for feat in const_variable.columns_imagefeat\n",
    "                    if row_dict.get(feat) != \"Unknown\"\n",
    "                )\n",
    "                if xray_descriptions:\n",
    "                    question += f\" Additional chest x-ray metadata include: {xray_descriptions}.\"\n",
    "\n",
    "            question = question.strip()\n",
    "            question = question.rstrip(\",.\")\n",
    "            if not question.endswith(\".\"):\n",
    "                question += \".\"\n",
    "\n",
    "            temp_instruct = {\"messages\": [\n",
    "                {\"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": system_prompt}\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": question},\n",
    "                    ],\n",
    "                },\n",
    "                {\"role\": \"assistant\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": answer}]},\n",
    "            ]}\n",
    "            if array_df[0] != None:\n",
    "                temp_instruct[\"messages\"][1]['content'].append({\"type\": \"audio\", \"audio\": array_df[0]})\n",
    "            if array_df[1] != None:\n",
    "                temp_instruct[\"messages\"][1]['content'].append({\"type\": \"image\", \"image\":array_df[1]})\n",
    "            instruct_array.append(temp_instruct)\n",
    "    \n",
    "    with open(f\"datas/instruct.pkl.{split}\", \"wb\") as f:\n",
    "        pickle.dump(instruct_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4e4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145652/10804767.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/o4-mini_symptoms.csv.test\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "/tmp/ipykernel_145652/10804767.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.test\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "Processing Datasets: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 22871.55it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.test\")\n",
    "df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/o4-mini_symptoms.csv.test\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) ) \n",
    "df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.test\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
    "df = pd.merge(df, df_llm_symptoms, on='barcode', how='left')\n",
    "df = pd.merge(df, df_llm_images, on='path_file_image', how='left')\n",
    "df = df.rename(columns={'coughdur': 'cough_duration', 'ngtsweats': 'night_sweets', 'weightloss': 'weight_loss', 'body_wt': 'body_weight'})\n",
    "\n",
    "instruct_array_positive = []\n",
    "instruct_array_negative = []\n",
    "\n",
    "for now_row in tqdm(df.itertuples(), desc=f\"Processing Datasets\", total=len(df)):\n",
    "    row_dict = now_row._asdict()\n",
    "    now_audiopath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_audio\n",
    "    now_imgaepath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_image\n",
    "\n",
    "    modalities = [\"audio\", \"xray\", \"symptoms\"]\n",
    "    key = tuple(modalities)\n",
    "    if key in const_variable.prompt_templates:\n",
    "        question = random.choice(const_variable.prompt_templates[key]) + \". \"\n",
    "    answer = commons.generate_tb_response(modalities, now_row.llm_analyze_symptoms, now_row.llm_analyze_image, positive=(now_row.ground_truth_tb == 1))\n",
    "\n",
    "    if now_row.path_file_audio == 'Unknown':\n",
    "        modalities = [m for m in modalities if m != \"audio\"]\n",
    "\n",
    "    array_df = [None, None]\n",
    "    if \"symptoms\" in modalities:\n",
    "        row_dict = now_row._asdict()\n",
    "        selected_feats = random.sample(const_variable.columns_soundfeat, k=random.randint(3, len(const_variable.columns_soundfeat)))\n",
    "        symptom_descriptions = \", \".join(\n",
    "            f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "            for feat in selected_feats\n",
    "            if row_dict.get(feat) != \"Unknown\"\n",
    "        )\n",
    "        if symptom_descriptions:\n",
    "            question += f\" Also, the patient presents with: {symptom_descriptions}.\"\n",
    "\n",
    "    if \"audio\" in modalities:\n",
    "        array_df[0] = now_audiopath\n",
    "\n",
    "    if \"xray\" in modalities:\n",
    "        array_df[1] = now_imgaepath\n",
    "        xray_descriptions = \", \".join(\n",
    "            f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "            for feat in const_variable.columns_imagefeat\n",
    "            if row_dict.get(feat) != \"Unknown\"\n",
    "        )\n",
    "        if xray_descriptions:\n",
    "            question += f\" Additional chest x-ray metadata include: {xray_descriptions}.\"\n",
    "\n",
    "    question = question.strip()\n",
    "    question = question.rstrip(\",.\")\n",
    "    if not question.endswith(\".\"):\n",
    "        question += \".\"\n",
    "\n",
    "    temp_instruct = {\"messages\": [\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": system_prompt}\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question},\n",
    "            ],\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": answer}]},\n",
    "    ]}\n",
    "    if array_df[0] != None:\n",
    "        temp_instruct[\"messages\"][1]['content'].append({\"type\": \"audio\", \"audio\": array_df[0]})\n",
    "    if array_df[1] != None:\n",
    "        temp_instruct[\"messages\"][1]['content'].append({\"type\": \"image\", \"image\":array_df[1]})\n",
    "\n",
    "    if now_row.ground_truth_tb == 1:\n",
    "        instruct_array_positive.append(temp_instruct)\n",
    "    elif now_row.ground_truth_tb == 0:\n",
    "        instruct_array_negative.append(temp_instruct)\n",
    "        \n",
    "with open(f\"datas/positive_instruct.pkl.test\", \"wb\") as f:\n",
    "    pickle.dump(instruct_array_positive, f)\n",
    "\n",
    "with open(f\"datas/negative_instruct.pkl.test\", \"wb\") as f:\n",
    "    pickle.dump(instruct_array_negative, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
