{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639c35f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ldap-users-2/dwipraseetyo-a/Project/Qwen2.5-Omni\n"
     ]
    }
   ],
   "source": [
    "%cd /home/is/dwipraseetyo-a/NAS_HAI/Project/Qwen2.5-Omni\n",
    "%pwd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import os, librosa, random, pickle, pydicom, requests, torch, re, shutil\n",
    "from pydicom.datadict import keyword_for_tag\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import commons, const_variable\n",
    "\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HG_AUTH_KEY_WRITE\"))\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "disease_map = {\n",
    "    \"Healthy\": 0,\n",
    "    \"Tuberculosis\": 1,\n",
    "    \"Covid-19\": 2,\n",
    "    \"Pneumonia\": 3,\n",
    "    \"Others\": 4,\n",
    "}\n",
    "disease_map_reverse = {v: k for k, v in disease_map.items()}\n",
    "\n",
    "prompt_templates = {\n",
    "    (\"audio\",): [\n",
    "        \"Based on the provided cough audio\",\n",
    "        \"Listen to this cough sound\",\n",
    "        \"Does the cough audio indicate\",\n",
    "        \"Analyze the following cough sound\"\n",
    "    ],\n",
    "    (\"xray\",): [\n",
    "        \"Examine this chest x-ray\",\n",
    "        \"Does the provided x-ray image show\",\n",
    "        \"Analyze the radiographic scan\",\n",
    "        \"From this x-ray image\"\n",
    "    ],\n",
    "    (\"symptoms\",): [\n",
    "        \"Given these symptoms\",\n",
    "        \"Do the presented symptoms indicate\",\n",
    "        \"Analyze the following symptoms\",\n",
    "        \"Based on the symptom description\"\n",
    "    ],\n",
    "    (\"audio\", \"xray\"): [\n",
    "        \"Based on the chest x-ray and cough audio\",\n",
    "        \"Examine the x-ray and cough sound\",\n",
    "        \"Given the radiograph and cough recording\",\n",
    "        \"Using both the x-ray and cough audio\"\n",
    "    ],\n",
    "    (\"audio\", \"symptoms\"): [\n",
    "        \"Given the cough audio and symptoms\",\n",
    "        \"Analyze the patient symptoms and cough\",\n",
    "        \"Do the symptoms and cough sound indicate\",\n",
    "        \"Using both the cough sound and symptoms\"\n",
    "    ],\n",
    "    (\"xray\", \"symptoms\"): [\n",
    "        \"From the x-ray and symptoms\",\n",
    "        \"Analyze the x-ray and clinical symptoms\",\n",
    "        \"Given the chest scan and symptoms\",\n",
    "        \"What is the diagnosis based on the x-ray and symptoms\"\n",
    "    ],\n",
    "    (\"audio\", \"xray\", \"symptoms\"): [\n",
    "        \"Based on the x-ray, cough audio, and symptoms\",\n",
    "        \"Evaluate the x-ray, cough sound, and symptoms\",\n",
    "        \"Given the combined evidence\",\n",
    "        \"Considering all inputs (image, sound, and symptoms)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "DESTINATION_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets\"\n",
    "\n",
    "system_prompt = '''\n",
    "You are an advanced medical assistant AI specialized in analyzing and diagnosing clinical conditions, capable of perceiving auditory and visual inputs. \n",
    "You can interpret and reason over various medical inputs, including auditory inputs, visual inputs, and patient symptoms, individually or in combination, depending on what is provided. \n",
    "Your task is to analyze the given input, explain your reasoning, and give a possible diagnosis. Always respond in the following format:\n",
    "<think>{Analyze the available data X-ray findings if present, cough audio characteristics if provided, and reported symptoms to determine the most likely disease.}</think>\n",
    "\n",
    "<answer>{Determined disease}</answer>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fffe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3386010/3721943634.py:5: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df1 = df1.groupby(\"user_id\", group_keys=False).apply(\n",
      "Processing val: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15070/15070 [04:55<00:00, 50.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for split in ['val']:\n",
    "    df1 = pd.read_csv(f\"{DATA_PATH}/coda/metadata_llm.csv.{split}\").rename(columns={\"participant\": \"user_id\", \"tb_status\": \"disease\", \"path_file\": \"path_file_audio\"})\n",
    "    df1 = df1[['user_id', 'disease', 'path_file_audio', 'symptoms_sentence', 'llm_analyze_symptoms']]\n",
    "    df1[\"disease\"] = df1[\"disease\"].replace(0, 4)\n",
    "    df1 = df1.groupby(\"user_id\", group_keys=False).apply(\n",
    "        lambda x: x.sample(n=min(len(x), 70), random_state=42)\n",
    "    )\n",
    "    df2 = pd.read_csv(f\"{DATA_PATH}/ukcovid/metadata_llm.csv.{split}\").rename(columns={\"participant_identifier\": \"user_id\", \"covid_test_result\": \"disease\"})\n",
    "    df2[\"disease\"] = df2[\"disease\"].replace(1, 2)\n",
    "    df2[\"disease\"] = df2[\"disease\"].replace(0, 4)\n",
    "    df2 = df2[['user_id', 'disease', 'path_file_audio', 'symptoms_sentence', 'llm_analyze_symptoms']]\n",
    "    df3 = pd.read_csv(f\"{DATA_PATH}/xray_metadata_llm_final.csv.{split}\").rename(columns={\"path_file\": \"path_file_image\", \"formatted_llm_analyze_image\": \"llm_analyze_image\"})\n",
    "    df_combined = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "    instruct_array = []\n",
    "    for now_row in tqdm(df_combined.itertuples(), desc=f\"Processing {split}\", total=len(df_combined)):\n",
    "        row_dict = now_row._asdict()\n",
    "        modalities = []\n",
    "        modalities_tags = \"\"\n",
    "        if not pd.isna(now_row.path_file_audio):\n",
    "            modalities_tags += \"<audio>\"\n",
    "            modalities.append(\"audio\")\n",
    "        if not pd.isna(now_row.path_file_image):\n",
    "            modalities_tags += \"<image>\"\n",
    "            modalities.append(\"xray\")\n",
    "        if not pd.isna(now_row.symptoms_sentence):\n",
    "            modalities.append(\"symptoms\")\n",
    "\n",
    "        key = tuple(modalities)\n",
    "        if key in prompt_templates:\n",
    "            last_sentence_question = random.choice(prompt_templates[key]) + \", Determine what disease this could indicate, or answer 'Others' if you cannot determine.\"\n",
    "        \n",
    "        question = \"\"\n",
    "        think_sentence = \"Okay, let's see. \"\n",
    "        if not pd.isna(now_row.llm_analyze_symptoms):\n",
    "            question += f\"The patient symptoms are {now_row.symptoms_sentence}.\"\n",
    "            think_sentence += now_row.llm_analyze_symptoms + \" \"\n",
    "        if not pd.isna(now_row.llm_analyze_image):\n",
    "            think_sentence += now_row.llm_analyze_image + \" \"\n",
    "        think_sentence += f\"Therefore, the disease is {disease_map_reverse[now_row.disease]}.\"\n",
    "        answer = f\"<think>{think_sentence}</think>\\n\\n<answer>{disease_map_reverse[now_row.disease]}</answer>\"\n",
    "\n",
    "        question = modalities_tags + \"\" + question\n",
    "        question += last_sentence_question\n",
    "\n",
    "        temp_instruct = {\"messages\": [\n",
    "            {\"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": system_prompt}\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": answer}]},\n",
    "        ]}\n",
    "\n",
    "        if not pd.isna(now_row.path_file_audio):\n",
    "            os.makedirs(f\"{DESTINATION_PATH}/{split}/\", exist_ok=True)\n",
    "            filename_audio = now_row.path_file_audio.split(\"/\")[-1].split(\".\")[0]\n",
    "            start_sec, end_sec = commons.random_3sec_segment(now_row.path_file_audio, segment_duration=3.0)\n",
    "            temp_instruct[\"messages\"][1]['content'].append({\n",
    "                \"type\": \"audio\", \n",
    "                \"audio\": f\"{filename_audio}.wav\",\n",
    "                \"audio_start\": float(start_sec),\n",
    "                \"audio_end\": float(end_sec)\n",
    "            })\n",
    "            #temp_instruct[\"audios\"] = now_row.path_file_audio\n",
    "            shutil.copy(now_row.path_file_audio, f\"{DESTINATION_PATH}/{split}/{filename_audio}.wav\")\n",
    "            temp_instruct[\"audio_file_name\"] = f\"{filename_audio}.wav\"\n",
    "        if not pd.isna(now_row.path_file_image):\n",
    "            filename_image = now_row.path_file_image.split(\"/\")[-1].split(\".\")[0]\n",
    "            temp_instruct[\"messages\"][1]['content'].append({\"type\": \"image\", \"image\": now_row.path_file_image.split(\"/\")[-1]})\n",
    "            #temp_instruct[\"images\"] = now_row.path_file_image\n",
    "            os.makedirs(f\"{DESTINATION_PATH}/{split}/\", exist_ok=True)\n",
    "            shutil.copy(now_row.path_file_image, f\"{DESTINATION_PATH}/{split}/{now_row.path_file_image.split('/')[-1]}\")\n",
    "            temp_instruct[\"image_file_name\"] = now_row.path_file_image.split(\"/\")[-1]\n",
    "\n",
    "        temp_instruct[\"solution\"] = answer\n",
    "        temp_instruct[\"identifier\"] = now_row.user_id\n",
    "        instruct_array.append(temp_instruct)\n",
    "\n",
    "    df_result = pd.DataFrame(instruct_array)\n",
    "    df_result.to_csv(f\"{DESTINATION_PATH}/{split}/metadata.csv\", index=False)\n",
    "\n",
    "    # train_instruct = commons.load_image_PIL(instruct_array, direct=True)  \n",
    "    # train_grpo = commons.grpo_build_datasets(train_instruct, None)\n",
    "    # train_dataset = Dataset.from_list(train_grpo)\n",
    "    # instruct_array = []\n",
    "    # train_dataset.push_to_hub(\n",
    "    #     \"arkiven4/medical-grpo-3modalities\",\n",
    "    #     split=split,\n",
    "    #     commit_message=f\"Upload Datasets\",\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f\"{DESTINATION_PATH}/val.csv\")\n",
    "# df.loc[df['audio_file_name'].notna(), 'audio_file_name'] =  \"val/\" + df.loc[df['audio_file_name'].notna(), 'audio_file_name']\n",
    "# df.loc[df['image_file_name'].notna(), 'image_file_name'] =  \"val/\" + df.loc[df['image_file_name'].notna(), 'image_file_name']\n",
    "# df.to_csv(f\"{DESTINATION_PATH}/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/val/\n",
    "# find . -type f ! -name \"val.tar.part.*\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/val/\n",
    "find . -type f ! -name \"*.tar\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75931255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: omnigrpo_dataset/default\n",
      "Using custom data configuration default-29bcee5a383d3676\n",
      "Loading Dataset Infos from /home/is/dwipraseetyo-a/.cache/huggingface/modules/datasets_modules/datasets/omnigrpo_dataset/98e8f5e8368e5a8f71a921eba3c315e3148c0ae1c2e47077a99b4fb7af564e84\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ New Version Processor2---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset omnigrpo_dataset (/home/is/dwipraseetyo-a/.cache/huggingface/datasets/omnigrpo_dataset/default-29bcee5a383d3676/1.0.0/98e8f5e8368e5a8f71a921eba3c315e3148c0ae1c2e47077a99b4fb7af564e84)\n",
      "Downloading and preparing dataset omnigrpo_dataset/default to /home/is/dwipraseetyo-a/.cache/huggingface/datasets/omnigrpo_dataset/default-29bcee5a383d3676/1.0.0/98e8f5e8368e5a8f71a921eba3c315e3148c0ae1c2e47077a99b4fb7af564e84...\n",
      "Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3387da4e9683481cac6b09281f736f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:644\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     fh = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileno\u001b[49m()\n\u001b[32m    645\u001b[39m     fp.flush()\n",
      "\u001b[31mAttributeError\u001b[39m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mHF_HOME\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m/home/is/dwipraseetyo-a/NAS_HAI/.cache\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m val_ds = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/omnigrpo_dataset.py\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                      \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/load.py:2151\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance.as_streaming_dataset(split=split)\n\u001b[32m   2150\u001b[39m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2151\u001b[39m \u001b[43mbuilder_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2157\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2159\u001b[39m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[32m   2160\u001b[39m keep_in_memory = (\n\u001b[32m   2161\u001b[39m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance.info.dataset_size)\n\u001b[32m   2162\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/builder.py:924\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    923\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[32m    931\u001b[39m \u001b[38;5;28mself\u001b[39m.info.dataset_size = \u001b[38;5;28msum\u001b[39m(split.num_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.splits.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/builder.py:1648\u001b[39m, in \u001b[36mGeneratorBasedBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[39m\n\u001b[32m   1647\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, **prepare_splits_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1648\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/builder.py:1000\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    996\u001b[39m split_dict.add(split_generator.split_info)\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    999\u001b[39m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m   1003\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot find data file. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1004\u001b[39m         + (\u001b[38;5;28mself\u001b[39m.manual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1005\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1006\u001b[39m         + \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m   1007\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/builder.py:1486\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split\u001b[39m\u001b[34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[39m\n\u001b[32m   1484\u001b[39m job_id = \u001b[32m0\u001b[39m\n\u001b[32m   1485\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m1486\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/builder.py:1624\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[39m\n\u001b[32m   1614\u001b[39m     shard_id += \u001b[32m1\u001b[39m\n\u001b[32m   1615\u001b[39m     writer = writer_class(\n\u001b[32m   1616\u001b[39m         features=writer._features,\n\u001b[32m   1617\u001b[39m         path=fpath.replace(\u001b[33m\"\u001b[39m\u001b[33mSSSSS\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshard_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33mJJJJJ\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1622\u001b[39m         embed_local_files=embed_local_files,\n\u001b[32m   1623\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m example = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m record\n\u001b[32m   1625\u001b[39m writer.write(example, key)\n\u001b[32m   1626\u001b[39m num_examples_progress_update += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/features/features.py:1996\u001b[39m, in \u001b[36mFeatures.encode_example\u001b[39m\u001b[34m(self, example)\u001b[39m\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example):\n\u001b[32m   1986\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1987\u001b[39m \u001b[33;03m    Encode example into a format for Arrow.\u001b[39;00m\n\u001b[32m   1988\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1994\u001b[39m \u001b[33;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[32m   1995\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m     example = \u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m encode_nested_example(\u001b[38;5;28mself\u001b[39m, example)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/features/features.py:459\u001b[39m, in \u001b[36mcast_to_python_objects\u001b[39m\u001b[34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcast_to_python_objects\u001b[39m(obj: Any, only_1d_for_numpy=\u001b[38;5;28;01mFalse\u001b[39;00m, optimize_list_casting=\u001b[38;5;28;01mTrue\u001b[39;00m) -> Any:\n\u001b[32m    440\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    441\u001b[39m \u001b[33;03m    Cast numpy/pytorch/tensorflow/pandas objects to python lists.\u001b[39;00m\n\u001b[32m    442\u001b[39m \u001b[33;03m    It works recursively.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m        casted_obj: the casted object\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize_list_casting\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/features/features.py:394\u001b[39m, in \u001b[36m_cast_to_python_objects\u001b[39m\u001b[34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[39m\n\u001b[32m    392\u001b[39m output = {}\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj.items():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     casted_v, has_changed_v = \u001b[43m_cast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize_list_casting\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m     has_changed |= has_changed_v\n\u001b[32m    398\u001b[39m     output[k] = casted_v\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/features/features.py:368\u001b[39m, in \u001b[36m_cast_to_python_objects\u001b[39m\u001b[34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[39m\n\u001b[32m    358\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    359\u001b[39m             [\n\u001b[32m    360\u001b[39m                 _cast_to_python_objects(\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    366\u001b[39m         )\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m config.PIL_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPIL\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys.modules \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PIL.Image.Image):\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pd.Series):\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    371\u001b[39m         _cast_to_python_objects(\n\u001b[32m    372\u001b[39m             obj.tolist(), only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimize_list_casting\n\u001b[32m    373\u001b[39m         )[\u001b[32m0\u001b[39m],\n\u001b[32m    374\u001b[39m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    375\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/features/image.py:315\u001b[39m, in \u001b[36mencode_pil_image\u001b[39m\u001b[34m(image)\u001b[39m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: image.filename, \u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mimage_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/datasets/features/image.py:307\u001b[39m, in \u001b[36mimage_to_bytes\u001b[39m\u001b[34m(image)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mformat\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mPNG\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image.mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRGBA\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mTIFF\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m buffer.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/PIL/Image.py:2588\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2585\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[32m   2587\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2588\u001b[39m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   2590\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/PIL/PngImagePlugin.py:1495\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, filename, chunk, save_all)\u001b[39m\n\u001b[32m   1491\u001b[39m     single_im = _write_multiple_frames(\n\u001b[32m   1492\u001b[39m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[32m   1493\u001b[39m     )\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_im:\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m     \u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[32m   1502\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info.chunks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:648\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    646\u001b[39m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io.UnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[33m\"\u001b[39m\u001b[33mflush\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    650\u001b[39m     fp.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:674\u001b[39m, in \u001b[36m_encode_tile\u001b[39m\u001b[34m(im, fp, tile, bufsize, fh, exc)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[32m    672\u001b[39m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m         errcode, data = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m:]\n\u001b[32m    675\u001b[39m         fp.write(data)\n\u001b[32m    676\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/home/is/dwipraseetyo-a/NAS_HAI/.cache\"\n",
    "\n",
    "val_ds = load_dataset(\"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/omnigrpo_dataset.py\", \n",
    "                      split='validation', data_dir=\"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets\", \n",
    "                      trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2b54770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging tar parts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.19s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7033bb30114b00989309a780cb5925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_config = {\n",
    "    \"LOADING_SCRIPT_FILES\": \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/my_audio_dataset.py\",\n",
    "    \"CONFIG_NAME\": \"val\",\n",
    "    \"DATA_DIR\": \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/\"\n",
    "}\n",
    "\n",
    "val_ds = load_dataset(\n",
    "    dataset_config[\"LOADING_SCRIPT_FILES\"],\n",
    "    dataset_config[\"CONFIG_NAME\"],\n",
    "    data_dir=dataset_config[\"DATA_DIR\"],\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6c5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/train.csv\")\n",
    "# df[\"audio_file_name\"] = \"train/\" + df[\"audio_file_name\"].astype(str)\n",
    "# df[\"image_file_name\"] = \"train/\" + df[\"image_file_name\"].astype(str)\n",
    "# df.to_csv(\"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/grpo_3modalities_datasets/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b3c22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>audio_file_name</th>\n",
       "      <th>solution</th>\n",
       "      <th>identifier</th>\n",
       "      <th>image_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/l_CODA_TB_0002_2.wav</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. Based on the patient's...</td>\n",
       "      <td>CODA_TB_0002</td>\n",
       "      <td>train/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/l_CODA_TB_0002_1.wav</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. Based on the patient's...</td>\n",
       "      <td>CODA_TB_0002</td>\n",
       "      <td>train/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/l_CODA_TB_0003_25.wav</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. Based on the provided ...</td>\n",
       "      <td>CODA_TB_0003</td>\n",
       "      <td>train/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/l_CODA_TB_0003_14.wav</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. Based on the provided ...</td>\n",
       "      <td>CODA_TB_0003</td>\n",
       "      <td>train/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/l_CODA_TB_0003_9.wav</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. Based on the provided ...</td>\n",
       "      <td>CODA_TB_0003</td>\n",
       "      <td>train/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100186</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/nan</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. The chest X-ray findin...</td>\n",
       "      <td>1GOVQY01H4M3</td>\n",
       "      <td>train/1GOVQY01H4M3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100187</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/nan</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. The chest X-ray findin...</td>\n",
       "      <td>RZY9JRW4JK4R</td>\n",
       "      <td>train/RZY9JRW4JK4R.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100188</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/nan</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. The chest X-ray findin...</td>\n",
       "      <td>BKZ6GYHYEV2Y</td>\n",
       "      <td>train/BKZ6GYHYEV2Y.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100189</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/nan</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. The chest X-ray findin...</td>\n",
       "      <td>0BTN61W0Y4LY</td>\n",
       "      <td>train/0BTN61W0Y4LY.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100190</th>\n",
       "      <td>[{'role': 'system', 'content': [{'type': 'text...</td>\n",
       "      <td>train/nan</td>\n",
       "      <td>&lt;think&gt;Okay, let's see. The chest X-ray findin...</td>\n",
       "      <td>ERSM47EVFOOD</td>\n",
       "      <td>train/ERSM47EVFOOD.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100191 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 messages  \\\n",
       "0       [{'role': 'system', 'content': [{'type': 'text...   \n",
       "1       [{'role': 'system', 'content': [{'type': 'text...   \n",
       "2       [{'role': 'system', 'content': [{'type': 'text...   \n",
       "3       [{'role': 'system', 'content': [{'type': 'text...   \n",
       "4       [{'role': 'system', 'content': [{'type': 'text...   \n",
       "...                                                   ...   \n",
       "100186  [{'role': 'system', 'content': [{'type': 'text...   \n",
       "100187  [{'role': 'system', 'content': [{'type': 'text...   \n",
       "100188  [{'role': 'system', 'content': [{'type': 'text...   \n",
       "100189  [{'role': 'system', 'content': [{'type': 'text...   \n",
       "100190  [{'role': 'system', 'content': [{'type': 'text...   \n",
       "\n",
       "                    audio_file_name  \\\n",
       "0        train/l_CODA_TB_0002_2.wav   \n",
       "1        train/l_CODA_TB_0002_1.wav   \n",
       "2       train/l_CODA_TB_0003_25.wav   \n",
       "3       train/l_CODA_TB_0003_14.wav   \n",
       "4        train/l_CODA_TB_0003_9.wav   \n",
       "...                             ...   \n",
       "100186                    train/nan   \n",
       "100187                    train/nan   \n",
       "100188                    train/nan   \n",
       "100189                    train/nan   \n",
       "100190                    train/nan   \n",
       "\n",
       "                                                 solution    identifier  \\\n",
       "0       <think>Okay, let's see. Based on the patient's...  CODA_TB_0002   \n",
       "1       <think>Okay, let's see. Based on the patient's...  CODA_TB_0002   \n",
       "2       <think>Okay, let's see. Based on the provided ...  CODA_TB_0003   \n",
       "3       <think>Okay, let's see. Based on the provided ...  CODA_TB_0003   \n",
       "4       <think>Okay, let's see. Based on the provided ...  CODA_TB_0003   \n",
       "...                                                   ...           ...   \n",
       "100186  <think>Okay, let's see. The chest X-ray findin...  1GOVQY01H4M3   \n",
       "100187  <think>Okay, let's see. The chest X-ray findin...  RZY9JRW4JK4R   \n",
       "100188  <think>Okay, let's see. The chest X-ray findin...  BKZ6GYHYEV2Y   \n",
       "100189  <think>Okay, let's see. The chest X-ray findin...  0BTN61W0Y4LY   \n",
       "100190  <think>Okay, let's see. The chest X-ray findin...  ERSM47EVFOOD   \n",
       "\n",
       "               image_file_name  \n",
       "0                    train/nan  \n",
       "1                    train/nan  \n",
       "2                    train/nan  \n",
       "3                    train/nan  \n",
       "4                    train/nan  \n",
       "...                        ...  \n",
       "100186  train/1GOVQY01H4M3.png  \n",
       "100187  train/RZY9JRW4JK4R.png  \n",
       "100188  train/BKZ6GYHYEV2Y.png  \n",
       "100189  train/0BTN61W0Y4LY.png  \n",
       "100190  train/ERSM47EVFOOD.png  \n",
       "\n",
       "[100191 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1334aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e356703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3057582/3122668694.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/gpt-4o-mini_symptoms.csv.{split}\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
      "/tmp/ipykernel_3057582/3122668694.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.{split}\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'dev']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.{split}\")\n",
    "    df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/gpt-4o-mini_symptoms.csv.{split}\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) ) \n",
    "    df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.{split}\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
    "    df = pd.merge(df, df_llm_symptoms, on='barcode', how='left')\n",
    "    df = pd.merge(df, df_llm_images, on='path_file_image', how='left')\n",
    "    df = df.rename(columns={'coughdur': 'cough_duration', 'ngtsweats': 'night_sweets', 'weightloss': 'weight_loss', 'body_wt': 'body_weight'})\n",
    "\n",
    "    case_info = df['ground_truth_tb'].value_counts().reset_index()\n",
    "    max_count = case_info['count'][0]\n",
    "    minor_count = case_info['count'][1]\n",
    "    ratio = int(max_count // minor_count)\n",
    "\n",
    "    #df_temp = pd.DataFrame(columns=['barcode', 'question', 'answer', 'tb_status', 'audio_path', 'image_path'])\n",
    "    instruct_array = []\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split}\", total=len(df)):\n",
    "        row_dict = now_row._asdict()\n",
    "        now_audiopath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_audio\n",
    "        now_imgaepath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_image\n",
    "        current_augment = ratio if now_row.ground_truth_tb == 1 else 1\n",
    "\n",
    "        for i in range(current_augment):\n",
    "            question = \"\"\n",
    "            array_df = [None, None]\n",
    "            last_sentence_question, modalities = commons.unique_modalities_generator(const_variable.prompt_templates, now_row.path_file_audio)\n",
    "            last_sentence_question += \". \"\n",
    "            #templates = const_variable.positive_templates if now_row.ground_truth_tb == 1 else const_variable.negative_templates\n",
    "            #answer = random.choice(templates)\n",
    "            answer = commons.generate_tb_response(modalities, now_row.llm_analyze_symptoms, now_row.llm_analyze_image, positive=(now_row.ground_truth_tb == 1))       \n",
    "            \n",
    "            array_df = [None, None]\n",
    "            modalities_tags = \"\"\n",
    "            if \"symptoms\" in modalities:\n",
    "                row_dict = now_row._asdict()\n",
    "                #selected_feats = random.sample(const_variable.columns_soundfeat, k=random.randint(3, len(const_variable.columns_soundfeat)))\n",
    "                symptom_descriptions = \", \".join(\n",
    "                    f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "                    for feat in const_variable.columns_soundfeat #selected_feats\n",
    "                    if row_dict.get(feat) != \"Unknown\"\n",
    "                )\n",
    "                if symptom_descriptions:\n",
    "                    question += f\"The patient symptoms are {symptom_descriptions}.\"\n",
    "\n",
    "            if \"audio\" in modalities:\n",
    "                modalities_tags += \"<audio>\"\n",
    "                array_df[0] = now_audiopath\n",
    "\n",
    "            if \"xray\" in modalities:\n",
    "                modalities_tags += \"<image>\"\n",
    "                array_df[1] = now_imgaepath\n",
    "                xray_descriptions = \", \".join(\n",
    "                    f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "                    for feat in const_variable.columns_imagefeat\n",
    "                    if row_dict.get(feat) != \"Unknown\"\n",
    "                )\n",
    "                if xray_descriptions:\n",
    "                    question += f\" The chest x-ray metadata are {xray_descriptions}.\"\n",
    "\n",
    "            question = question.strip()\n",
    "            question = question.rstrip(\",.\")\n",
    "            if not question.endswith(\".\"):\n",
    "                question += \". \"\n",
    "            \n",
    "            question = modalities_tags + \"\" + question\n",
    "            # temp_sentence_arry = last_sentence_question.split(\",\")\n",
    "            # if len(temp_sentence_arry) >= 2:\n",
    "            #     temp_sentence_arry[-2] += \" \" + modalities_tags\n",
    "            # question += \",\".join(temp_sentence_arry)\n",
    "            question += last_sentence_question\n",
    "\n",
    "            temp_instruct = {\"messages\": [\n",
    "                {\"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": system_prompt}\n",
    "                    ],\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": question},\n",
    "                    ],\n",
    "                },\n",
    "                {\"role\": \"assistant\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": answer}]},\n",
    "            ]}\n",
    "            if array_df[0] != None:\n",
    "                temp_instruct[\"messages\"][1]['content'].append({\"type\": \"audio\", \"audio\": array_df[0]})\n",
    "            if array_df[1] != None:\n",
    "                temp_instruct[\"messages\"][1]['content'].append({\"type\": \"image\", \"image\": array_df[1]})\n",
    "            instruct_array.append(temp_instruct)            \n",
    "            #df_temp.loc[len(df_temp)] = [now_row.barcode, question, answer, now_row.ground_truth_tb, now_audiopath, now_imgaepath]\n",
    "    with open(f\"datas/instruct_sft_balance.pkl.{split}\", \"wb\") as f:\n",
    "        pickle.dump(instruct_array, f)\n",
    "    #pd.DataFrame(df_temp).to_csv(f'datas/grpo_balance.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83eb0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ceea336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative Tuberculosis'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'<answer>(.*?)</answer>', \"<answer> Negative Tuberculosis </answer>\", flags=re.IGNORECASE).group(1).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e87355f",
   "metadata": {},
   "source": [
    "# Publish To HG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bc439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "| 📦 Loading Dataset... |\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3526/3526 [00:31<00:00, 112.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 439/439 [00:03<00:00, 114.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3526/3526 [00:55<00:00, 63.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 439/439 [00:04<00:00, 99.13it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675633f99b2a4438922e08c4fbaf9641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa000e4c14c4cee82c17fbef2ffd6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be11a6ad1174f70918fa3f2bd696ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeeb217519f444fa9c439aca43f482e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b54229136f6400ea401f653d16d092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/arkiven4/cirdz-instruct/commit/8538285dc2f17ddce47fb960f49054e6c7d10419', commit_message='Upload dataset', commit_description='', oid='8538285dc2f17ddce47fb960f49054e6c7d10419', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/arkiven4/cirdz-instruct', endpoint='https://huggingface.co', repo_type='dataset', repo_id='arkiven4/cirdz-instruct'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HG_AUTH_KEY_WRITE\"))\n",
    "\n",
    "commons.pretty_status(\"📦 Loading Dataset...\")\n",
    "\n",
    "with open('datas/instruct_grpo_balance.pkl.train', 'rb') as f:\n",
    "    train_instruct = commons.load_image_PIL(pickle.load(f))\n",
    "\n",
    "with open('datas/instruct_grpo_balance.pkl.dev', 'rb') as f:\n",
    "    dev_instruct = commons.load_image_PIL(pickle.load(f))\n",
    "    \n",
    "train_dataset = Dataset.from_list(commons.grpo_build_datasets(train_instruct, None)) #\n",
    "val_dataset = Dataset.from_list(commons.grpo_build_datasets(dev_instruct, None))\n",
    "\n",
    "combined = concatenate_datasets([train_dataset, val_dataset])\n",
    "combined.push_to_hub(\"arkiven4/cirdz-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.test\")\n",
    "df_llm_symptoms = ( pd.read_csv(f\"datas/reasoning/symptoms/o4-mini_symptoms.csv.test\").groupby('barcode', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) ) \n",
    "df_llm_images = ( pd.read_csv(f\"datas/reasoning/xray/medgemma_xray_formatted.csv.test\").groupby('path_file_image', group_keys=False).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True) )\n",
    "df = pd.merge(df, df_llm_symptoms, on='barcode', how='left')\n",
    "df = pd.merge(df, df_llm_images, on='path_file_image', how='left')\n",
    "df = df.rename(columns={'coughdur': 'cough_duration', 'ngtsweats': 'night_sweets', 'weightloss': 'weight_loss', 'body_wt': 'body_weight'})\n",
    "\n",
    "instruct_array_positive = []\n",
    "instruct_array_negative = []\n",
    "\n",
    "for now_row in tqdm(df.itertuples(), desc=f\"Processing Datasets\", total=len(df)):\n",
    "    row_dict = now_row._asdict()\n",
    "    now_audiopath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_audio\n",
    "    now_imgaepath = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" +  now_row.path_file_image\n",
    "\n",
    "    modalities = [\"audio\", \"xray\", \"symptoms\"]\n",
    "    key = tuple(modalities)\n",
    "    if key in const_variable.prompt_templates:\n",
    "        question = random.choice(const_variable.prompt_templates[key]) + \". \"\n",
    "    answer = commons.generate_tb_response(modalities, now_row.llm_analyze_symptoms, now_row.llm_analyze_image, positive=(now_row.ground_truth_tb == 1))\n",
    "\n",
    "    if now_row.path_file_audio == 'Unknown':\n",
    "        modalities = [m for m in modalities if m != \"audio\"]\n",
    "\n",
    "    array_df = [None, None]\n",
    "    if \"symptoms\" in modalities:\n",
    "        row_dict = now_row._asdict()\n",
    "        selected_feats = random.sample(const_variable.columns_soundfeat, k=random.randint(3, len(const_variable.columns_soundfeat)))\n",
    "        symptom_descriptions = \", \".join(\n",
    "            f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "            for feat in selected_feats\n",
    "            if row_dict.get(feat) != \"Unknown\"\n",
    "        )\n",
    "        if symptom_descriptions:\n",
    "            question += f\" Also, the patient presents with: {symptom_descriptions}.\"\n",
    "\n",
    "    if \"audio\" in modalities:\n",
    "        array_df[0] = now_audiopath\n",
    "\n",
    "    if \"xray\" in modalities:\n",
    "        array_df[1] = now_imgaepath\n",
    "        xray_descriptions = \", \".join(\n",
    "            f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "            for feat in const_variable.columns_imagefeat\n",
    "            if row_dict.get(feat) != \"Unknown\"\n",
    "        )\n",
    "        if xray_descriptions:\n",
    "            question += f\" Additional chest x-ray metadata include: {xray_descriptions}.\"\n",
    "\n",
    "    question = question.strip()\n",
    "    question = question.rstrip(\",.\")\n",
    "    if not question.endswith(\".\"):\n",
    "        question += \".\"\n",
    "\n",
    "    temp_instruct = {\"messages\": [\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": system_prompt}\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question},\n",
    "            ],\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": answer}]},\n",
    "    ]}\n",
    "    if array_df[0] != None:\n",
    "        temp_instruct[\"messages\"][1]['content'].append({\"type\": \"audio\", \"audio\": array_df[0]})\n",
    "    if array_df[1] != None:\n",
    "        temp_instruct[\"messages\"][1]['content'].append({\"type\": \"image\", \"image\":array_df[1]})\n",
    "\n",
    "    if now_row.ground_truth_tb == 1:\n",
    "        instruct_array_positive.append(temp_instruct)\n",
    "    elif now_row.ground_truth_tb == 0:\n",
    "        instruct_array_negative.append(temp_instruct)\n",
    "        \n",
    "with open(f\"datas/positive_instruct.pkl.test\", \"wb\") as f:\n",
    "    pickle.dump(instruct_array_positive, f)\n",
    "\n",
    "with open(f\"datas/negative_instruct.pkl.test\", \"wb\") as f:\n",
    "    pickle.dump(instruct_array_negative, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
