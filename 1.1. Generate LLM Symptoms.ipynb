{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657bdbd7",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1b132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ldap-users-2/dwipraseetyo-a/Project/Qwen2.5-Omni\n"
     ]
    }
   ],
   "source": [
    "%cd /home/is/dwipraseetyo-a/NAS_HAI/Project/Qwen2.5-Omni\n",
    "%pwd\n",
    "\n",
    "import commons, const_variable\n",
    "import os, librosa, random, pickle, pydicom, requests, torch, re, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c282a37",
   "metadata": {},
   "source": [
    "# Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d49c9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You are a clinical reasoning assistant specialized in respiratory diseases, particularly Tuberculosis (TB).\n",
    "The user will provide a label (True for TB, False for not TB) along with a list of symptoms. Treat the label as ground truth.\n",
    "Your task is to perform detailed clinical reasoning by analyzing the provided symptoms and explaining why they support or contradict the TB diagnosis.\n",
    "Output format: JSONL with one key 'answer'\n",
    "The value should be a short paragraph of clinical reasoning, grounded in the symptoms.\n",
    "'''\n",
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33aa1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:   0%|                                                                                                                                                                                             | 0/2151 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2151/2151 [1:47:50<00:00,  3.01s/it]\n",
      "Processing dev: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 269/269 [12:51<00:00,  2.87s/it]\n",
      "Processing test: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 270/270 [13:04<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.{split}\")\n",
    "    df = df.rename(columns={'coughdur': 'cough_duration', 'ngtsweats': 'night_sweets', 'weightloss': 'weight_loss', 'body_wt': 'body_weight'})\n",
    "\n",
    "    df_temp = pd.DataFrame(columns=['barcode', 'llm_analyze_symptoms'])\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split}\", total=len(df)):\n",
    "        row_dict = now_row._asdict()\n",
    "        now_barcode = now_row.barcode\n",
    "        answer = \"This is Tuberculosis Positive\" if now_row.ground_truth_tb == 1 else \"This is Tuberculosis Negative\"\n",
    "        question = \", \".join(\n",
    "            f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "            for feat in const_variable.columns_soundfeat\n",
    "            if row_dict.get(feat) != \"Unknown\"\n",
    "        )\n",
    "\n",
    "        response = const_variable.clientOpenAI.chat.completions.create(\n",
    "            model=\"gpt-4.1\",  # o4-mini gpt-4o-mini gpt-4.1\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{answer}. The Patient Symptoms Are: {question}\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        safe_content = re.sub(r'(?<!\\\\)\\n', r'\\\\n', response.choices[0].message.content.replace(\"{\\n\", \"{\").replace(\"\\n}\", \"}\"))\n",
    "        if not safe_content.endswith('}'):\n",
    "            safe_content += '}'\n",
    "        response_json = json.loads(safe_content)\n",
    "        llm_answer = response_json['answer']\n",
    "        df_temp.loc[len(df_temp)] = [now_barcode, llm_answer]\n",
    "    pd.DataFrame(df_temp).to_csv(f'datas/reasoning/symptoms/gpt41_symptoms.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd12cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for now_row in tqdm(df.itertuples(), desc=f\"Processing {split}\", total=len(df)):\n",
    "    count += 1\n",
    "    if count <= 620:\n",
    "        continue\n",
    "    \n",
    "    row_dict = now_row._asdict()\n",
    "    now_barcode = now_row.barcode\n",
    "    answer = \"This is Tuberculosis\" if now_row.ground_truth_tb == 1 else \"This is Not Tuberculosis\"\n",
    "    question = \", \".join(\n",
    "        f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "        for feat in const_variable.columns_soundfeat\n",
    "        if row_dict.get(feat) != \"Unknown\"\n",
    "    )\n",
    "\n",
    "    response = const_variable.clientOpenAI.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # o4-mini gpt-4o-mini\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"{answer}. The Patient Symptoms Are: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    safe_content = re.sub(r'(?<!\\\\)\\n', r'\\\\n', response.choices[0].message.content.replace(\"{\\n\", \"{\").replace(\"\\n}\", \"}\"))\n",
    "    if not safe_content.endswith('}'):\n",
    "        safe_content += '}'\n",
    "    response_json = json.loads(safe_content)\n",
    "    llm_answer = response_json['answer']\n",
    "    df_temp.loc[len(df_temp)] = [now_barcode, llm_answer]\n",
    "pd.DataFrame(df_temp).to_csv(f'datas/reasoning/symptoms/gpt4_symptoms.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce851826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "def process_row(now_row):\n",
    "    row_dict = now_row._asdict()\n",
    "    now_barcode = now_row.barcode\n",
    "    answer = \"This is Tuberculosis\" if now_row.ground_truth_tb == 1 else \"This is Not Tuberculosis\"\n",
    "    \n",
    "    question = \", \".join(\n",
    "        f\"{feat.replace('_', ' ')} is {row_dict[feat]}\"\n",
    "        for feat in const_variable.columns_soundfeat\n",
    "        if row_dict.get(feat) != \"Unknown\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = const_variable.clientOpenAI.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{answer}. The Patient Symptoms Are: {question}\"}\n",
    "            ]\n",
    "        )\n",
    "        safe_content = re.sub(r'(?<!\\\\)\\n', r'\\\\n', response.choices[0].message.content.replace(\"{\\n\", \"{\").replace(\"\\n}\", \"}\"))\n",
    "        if not safe_content.endswith('}'):\n",
    "            safe_content += '}'\n",
    "\n",
    "        response_json = json.loads(safe_content)\n",
    "        llm_answer = response_json['answer']\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {now_barcode}: {e}\")\n",
    "        llm_answer = \"Error\"\n",
    "\n",
    "    return now_barcode, llm_answer\n",
    "\n",
    "\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.{split}\")\n",
    "    df = df.rename(columns={\n",
    "        'coughdur': 'cough_duration',\n",
    "        'ngtsweats': 'night_sweets',\n",
    "        'weightloss': 'weight_loss',\n",
    "        'body_wt': 'body_weight'\n",
    "    })\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = list(tqdm(\n",
    "            executor.map(process_row, df.itertuples(index=False)),\n",
    "            total=len(df),\n",
    "            desc=f\"Processing {split}\"\n",
    "        ))\n",
    "\n",
    "    # Collect results\n",
    "    for barcode, llm_answer in futures:\n",
    "        results.append({'barcode': barcode, 'llm_analyze_symptoms': llm_answer})\n",
    "\n",
    "    df_temp = pd.DataFrame(results)\n",
    "    df_temp.to_csv(f'datas/reasoning/symptoms/gpt41_symptoms.csv.{split}', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
