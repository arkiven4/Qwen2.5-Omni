{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657bdbd7",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1b132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ldap-users-2/dwipraseetyo-a/Project/Qwen2.5-Omni\n"
     ]
    }
   ],
   "source": [
    "%cd /home/is/dwipraseetyo-a/NAS_HAI/Project/Qwen2.5-Omni\n",
    "%pwd\n",
    "\n",
    "import commons, const_variable\n",
    "import os, librosa, random, pickle, pydicom, requests, torch, re, json, pydicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def fix_broken_bullet_blocks(text):\n",
    "    lines = text.splitlines()\n",
    "    fixed_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        # Detect pattern:\n",
    "        # Line i: startswith \"*   Something\"\n",
    "        # Line i+1: is \"*\"\n",
    "        # Line i+2: startswith \"*   SomethingElse\"\n",
    "        if line.startswith(\"*\") and not line == \"*\" and i + 2 < len(lines):\n",
    "            next_line = lines[i + 1].strip()\n",
    "            next_next_line = lines[i + 2].strip()\n",
    "            if next_line == \"*\" and next_next_line.startswith(\"*\"):\n",
    "                # Add current line\n",
    "                fixed_lines.append(lines[i])\n",
    "                # Merge next_next_line as continuation bullet\n",
    "                fixed_lines.append(\"    \" + next_next_line)\n",
    "                i += 3\n",
    "                continue\n",
    "\n",
    "        # If not matching pattern, just add the line\n",
    "        fixed_lines.append(lines[i])\n",
    "        i += 1\n",
    "\n",
    "    return \"\\n\".join(fixed_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c282a37",
   "metadata": {},
   "source": [
    "# Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b86e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"/home/is/dwipraseetyo-a/NAS_HAI/Project/pretrain/medgemma-4b-it\"\n",
    "auth_key = os.getenv(\"HG_AUTH_KEY\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    token=auth_key,\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "processor.tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49c9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dev,:   0%|                                                                                                                                                                                               | 0/269 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for split in ['dev', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.{split}\")\n",
    "    results = []\n",
    "    paths = []\n",
    "    images = []\n",
    "    messages_batch = []\n",
    "\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split},\", total=len(df)):\n",
    "        now_path = now_row.path_file_image\n",
    "        now_image = commons.crop_and_convert(\"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" + now_path)\n",
    "        answer = \"This is Tuberculosis\" if now_row.ground_truth_tb == 1 else \"This is Not Tuberculosis\"\n",
    "        system_prompt = (\n",
    "            \"You are an expert radiologist. Analyze the chest X-ray and return only the following sections:\\n\\n\"\n",
    "            \"**Specific Findings:** Provide a comprehensive and detailed description of all relevant radiographic abnormalities.\\n\\n\"\n",
    "            \"**Differential Diagnosis:** Only if the X-ray not healty and describe the reason.\\n\\n\"\n",
    "            \"**Conclusion:** Summarize your diagnostic impression clearly.\\n\\n\"\n",
    "            \"Do not include any **Disclaimer** or unrelated content.\"\n",
    "        ) if now_row.ground_truth_tb == 0 else (\n",
    "            \"You are an expert radiologist. Analyze the chest X-ray and return only the following sections:\\n\\n\"\n",
    "            \"**Key Features:** Highlight radiographic patterns that are characteristic of tuberculosis, explained clearly and in detail.\\n\\n\"\n",
    "            \"**Conclusion:** Summarize your diagnostic impression clearly.\\n\\n\"\n",
    "            \"Do not include any **Disclaimer** or unrelated content.\"\n",
    "        )\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system_prompt}]},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"Describe the X-ray.\" + answer},\n",
    "                {\"type\": \"image\", \"image\": now_image}\n",
    "            ]}\n",
    "        ]\n",
    "        paths.append(now_path)\n",
    "        messages_batch.append(message)\n",
    "\n",
    "    # Process in batches\n",
    "    batch_size = 24\n",
    "    for i in tqdm(range(0, len(messages_batch), batch_size), desc=\"Generating\", total=len(range(0, len(messages_batch), batch_size))):\n",
    "        batch_messages = messages_batch[i:i+batch_size]\n",
    "        batch_paths = paths[i:i+batch_size]\n",
    "\n",
    "        inputs = processor.apply_chat_template(batch_messages, add_generation_prompt=True, tokenize=True,\n",
    "                                               return_dict=True, return_tensors=\"pt\", padding=True).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_lens = [len(ids) for ids in inputs['input_ids']]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            generation = model.generate(**inputs, max_new_tokens=768, do_sample=False)\n",
    "\n",
    "        # Slice outputs to exclude input prompt\n",
    "        for j in range(len(batch_messages)):\n",
    "            output_ids = generation[j][input_lens[j]:]\n",
    "            decoded = processor.decode(output_ids, skip_special_tokens=True)\n",
    "            results.append({\n",
    "                \"path_file_image\": batch_paths[j],\n",
    "                \"llm_analyze_image\": decoded\n",
    "            })\n",
    "    pd.DataFrame(results).to_csv(f'datas/reasoning/xray/medgemma_xray.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d8059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train,: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2151/2151 [00:02<00:00, 786.99it/s]\n",
      "Processing dev,: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:00<00:00, 835.83it/s]\n",
      "Processing test,: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 270/270 [00:00<00:00, 828.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f\"datas/reasoning/xray/medgemma_xray.csv.{split}\")\n",
    "    df = df.rename(columns={'coughdur': 'cough_duration', 'ngtsweats': 'night_sweets', 'weightloss': 'weight_loss', 'body_wt': 'body_weight'})\n",
    "\n",
    "    df_temp = pd.DataFrame(columns=['path_file_image', 'llm_analyze_image'])\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split},\", total=len(df)):\n",
    "        now_path = now_row.path_file_image\n",
    "        text = now_row.llm_analyze_image\n",
    "\n",
    "        section_pattern = r'(?:\\*\\*)?\\{?([A-Za-z ]+?)\\}?:?(?:\\*\\*)?\\n\\n|(?:\\.\\n\\n)?([A-Za-z ]+?):\\n\\n'\n",
    "        matches = list(re.finditer(section_pattern, text))\n",
    "        parsed = []\n",
    "\n",
    "        start = 0\n",
    "        for i, match in enumerate(matches):\n",
    "            title = match.group(1) or match.group(2)\n",
    "            title = title.strip()\n",
    "\n",
    "            content_start = match.end()\n",
    "            content_end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "            content = text[content_start:content_end].strip()\n",
    "\n",
    "            disclaimer = re.search(r'\\n\\n\\*?\\*?Disclaimer:.*', content, re.IGNORECASE | re.DOTALL)\n",
    "            if disclaimer:\n",
    "                content = content[:disclaimer.start()].strip()\n",
    "            parsed.append((title, content))\n",
    "        \n",
    "        extracted_data = \"\\n\\n\"\n",
    "        for idx, (title, content) in enumerate(parsed):\n",
    "            if idx == len(parsed) - 1:\n",
    "                extracted_data += f\"{content.replace('*   ', '')}\" + \" \\n\\n\"\n",
    "            else:\n",
    "                extracted_data += f\"* {title}\\n{content.replace('*   ', '    *   ')}\" + \" \\n\\n\"\n",
    "        \n",
    "        df_temp.loc[len(df_temp)] = [now_path, fix_broken_bullet_blocks(extracted_data)]\n",
    "    pd.DataFrame(df_temp).to_csv(f'datas/reasoning/xray/medgemma_xray_formatted.csv.{split}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
