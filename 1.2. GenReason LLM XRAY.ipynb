{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657bdbd7",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d1b132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ldap-users-2/dwipraseetyo-a/Project/Qwen2.5-Omni\n",
      "CUDA_VISIBLE_DEVICES: 0,1\n"
     ]
    }
   ],
   "source": [
    "%cd /home/is/dwipraseetyo-a/NAS_HAI/Project/Qwen2.5-Omni\n",
    "%pwd\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "import commons, const_variable\n",
    "import os, librosa, random, pickle, pydicom, requests, torch, re, json, pydicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def fix_broken_bullet_blocks(text):\n",
    "    lines = text.splitlines()\n",
    "    fixed_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        # Detect pattern:\n",
    "        # Line i: startswith \"*   Something\"\n",
    "        # Line i+1: is \"*\"\n",
    "        # Line i+2: startswith \"*   SomethingElse\"\n",
    "        if line.startswith(\"*\") and not line == \"*\" and i + 2 < len(lines):\n",
    "            next_line = lines[i + 1].strip()\n",
    "            next_next_line = lines[i + 2].strip()\n",
    "            if next_line == \"*\" and next_next_line.startswith(\"*\"):\n",
    "                # Add current line\n",
    "                fixed_lines.append(lines[i])\n",
    "                # Merge next_next_line as continuation bullet\n",
    "                fixed_lines.append(\"    \" + next_next_line)\n",
    "                i += 3\n",
    "                continue\n",
    "\n",
    "        # If not matching pattern, just add the line\n",
    "        fixed_lines.append(lines[i])\n",
    "        i += 1\n",
    "\n",
    "    return \"\\n\".join(fixed_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c282a37",
   "metadata": {},
   "source": [
    "# Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b86e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef988554c948c891e39cf52049e15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"/home/is/dwipraseetyo-a/NAS_HAI/Project/pretrain/medgemma-4b-it\"\n",
    "auth_key = os.getenv(\"HG_AUTH_KEY\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    token=auth_key,\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "processor.tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train,: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2173/2173 [00:50<00:00, 42.93it/s]\n",
      "Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [23:34<00:00, 15.54s/it]\n",
      "Processing dev,: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 272/272 [00:06<00:00, 43.89it/s]\n",
      "Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [03:07<00:00, 15.59s/it]\n",
      "Processing test,: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 272/272 [00:06<00:00, 41.35it/s]\n",
      "Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [03:02<00:00, 15.23s/it]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/metadata_cut_processed.csv.{split}\")\n",
    "    results = []\n",
    "    paths = []\n",
    "    images = []\n",
    "    messages_batch = []\n",
    "\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split},\", total=len(df)):\n",
    "        now_path = now_row.path_file_image\n",
    "        now_image = commons.crop_and_convert(\"/home/is/dwipraseetyo-a/NAS_HAI/Datasets/cidrz/\" + now_path)\n",
    "        answer = \"This is Tuberculosis\" if now_row.ground_truth_tb == 1 else \"This is Not Tuberculosis\"\n",
    "        system_prompt = (\n",
    "            \"You are an expert radiologist. Analyze the chest X-ray and return only the following sections:\\n\\n\"\n",
    "            \"**Specific Findings:** Provide a comprehensive and detailed description of all relevant radiographic abnormalities.\\n\\n\"\n",
    "            \"**Differential Diagnosis:** Only if the X-ray not healty and describe the reason.\\n\\n\"\n",
    "            \"**Conclusion:** Summarize your diagnostic impression clearly.\\n\\n\"\n",
    "            \"Do not include any **Disclaimer** or unrelated content.\"\n",
    "        ) if now_row.ground_truth_tb == 0 else (\n",
    "            \"You are an expert radiologist. Analyze the chest X-ray and return only the following sections:\\n\\n\"\n",
    "            \"**Key Features:** Highlight radiographic patterns that are characteristic of tuberculosis, explained clearly and in detail.\\n\\n\"\n",
    "            \"**Conclusion:** Summarize your diagnostic impression clearly.\\n\\n\"\n",
    "            \"Do not include any **Disclaimer** or unrelated content.\"\n",
    "        )\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system_prompt}]},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"Describe the X-ray.\" + answer},\n",
    "                {\"type\": \"image\", \"image\": now_image}\n",
    "            ]}\n",
    "        ]\n",
    "        paths.append(now_path)\n",
    "        messages_batch.append(message)\n",
    "\n",
    "    # Process in batches\n",
    "    batch_size = 24\n",
    "    for i in tqdm(range(0, len(messages_batch), batch_size), desc=\"Generating\", total=len(range(0, len(messages_batch), batch_size))):\n",
    "        batch_messages = messages_batch[i:i+batch_size]\n",
    "        batch_paths = paths[i:i+batch_size]\n",
    "\n",
    "        inputs = processor.apply_chat_template(batch_messages, add_generation_prompt=True, tokenize=True,\n",
    "                                               return_dict=True, return_tensors=\"pt\", padding=True).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_lens = [len(ids) for ids in inputs['input_ids']]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            generation = model.generate(**inputs, max_new_tokens=768, do_sample=False)\n",
    "\n",
    "        # Slice outputs to exclude input prompt\n",
    "        for j in range(len(batch_messages)):\n",
    "            output_ids = generation[j][input_lens[j]:]\n",
    "            decoded = processor.decode(output_ids, skip_special_tokens=True)\n",
    "            results.append({\n",
    "                \"path_file_image\": batch_paths[j],\n",
    "                \"llm_analyze_image\": decoded\n",
    "            })\n",
    "    pd.DataFrame(results).to_csv(f'datas/reasoning/xray/medgemma_xray.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90d10cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_convert(path_file, max_size=1024):\n",
    "    array_PIL = Image.open(path_file)\n",
    "    \n",
    "    # Resize if needed\n",
    "    width, height = array_PIL.size\n",
    "    max_dim = max(width, height)\n",
    "    \n",
    "    if max_dim > max_size:\n",
    "        scale = max_size / max_dim\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        array_PIL = array_PIL.resize((new_width, new_height), resample=Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return array_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_map = {\n",
    "    \"Normal\": 0,\n",
    "    \"Tuberculosis\": 1,\n",
    "    \"Covid-19\": 2,\n",
    "    \"Pneumonia\": 3,\n",
    "    \"Other\": 3,\n",
    "}\n",
    "reverse_map = {v: k for k, v in disease_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6359654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disease\n",
       "0    12227\n",
       "3    10499\n",
       "1     5386\n",
       "4     4418\n",
       "2     3068\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train,:   0%|                                                                                                                                               | 0/35598 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train,:   0%|                                                                                                                                               | 0/35598 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "for split in ['train', 'val', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/xray_metadata_llm.csv.{split}\")\n",
    "    results = []\n",
    "    paths = []\n",
    "    images = []\n",
    "    messages_batch = []\n",
    "\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split},\", total=len(df)):\n",
    "        now_path = now_row.path_file\n",
    "        now_image = crop_and_convert(now_path)\n",
    "        answer = f\"This is {reverse_map[now_row.disease]} Disease\"\n",
    "        system_prompt = (\n",
    "            \"You are an expert radiologist. Analyze the chest X-ray and return only the following sections:\\n\\n\"\n",
    "            \"**Specific Findings:** Provide a comprehensive and detailed description of all relevant radiographic abnormalities.\\n\\n\"\n",
    "            \"**Differential Diagnosis:** Only if the X-ray not healty and describe the reason.\\n\\n\"\n",
    "            \"**Conclusion:** Summarize your diagnostic impression clearly.\\n\\n\"\n",
    "            \"Do not include any **Disclaimer** or unrelated content.\"\n",
    "        ) if now_row.disease == 0 else (\n",
    "            \"You are an expert radiologist. Analyze the chest X-ray and return only the following sections:\\n\\n\"\n",
    "            \"**Key Features:** Highlight radiographic patterns that are characteristic of disease, explained clearly and in detail.\\n\\n\"\n",
    "            \"**Conclusion:** Summarize your diagnostic impression clearly.\\n\\n\"\n",
    "            \"Do not include any **Disclaimer** or unrelated content.\"\n",
    "        )\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system_prompt}]},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"Describe the X-ray.\" + answer},\n",
    "                {\"type\": \"image\", \"image\": now_image}\n",
    "            ]}\n",
    "        ]\n",
    "        paths.append(now_path)\n",
    "        messages_batch.append(message)\n",
    "\n",
    "    batch_size = 24\n",
    "    for i in tqdm(range(0, len(messages_batch), batch_size), desc=\"Generating\", total=len(range(0, len(messages_batch), batch_size))):\n",
    "        batch_messages = messages_batch[i:i+batch_size]\n",
    "        batch_paths = paths[i:i+batch_size]\n",
    "\n",
    "        inputs = processor.apply_chat_template(batch_messages, add_generation_prompt=True, tokenize=True,\n",
    "                                               return_dict=True, return_tensors=\"pt\", padding=True).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_lens = [len(ids) for ids in inputs['input_ids']]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            generation = model.generate(**inputs, max_new_tokens=768, do_sample=False)\n",
    "\n",
    "        # Slice outputs to exclude input prompt\n",
    "        for j in range(len(batch_messages)):\n",
    "            output_ids = generation[j][input_lens[j]:]\n",
    "            decoded = processor.decode(output_ids, skip_special_tokens=True)\n",
    "            results.append({\n",
    "                \"path_file_image\": batch_paths[j],\n",
    "                \"llm_analyze_image\": decoded\n",
    "            })\n",
    "\n",
    "    results_df.to_csv(f\"{DATA_PATH}/asdasd.csv.{split}\", index=False)\n",
    "    merged = df.merge(\n",
    "        results_df.rename(columns={\"idx_col\": IDX_COL}),\n",
    "        on=IDX_COL,\n",
    "        how=\"left\"\n",
    "    )\n",
    "    merged.to_csv(f\"{DATA_PATH}/metadata_llm.csv.{split}\", index=False)\n",
    "    # pd.DataFrame(results).to_csv(f'datas/reasoning/xray/medgemma_xray.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f994c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Key Features:**\\n\\nThe chest X-ray demonstrates diffuse, bilateral interstitial infiltrates, predominantly in the lower lung zones. These infiltrates appear as hazy opacities, often with a reticular or nodular pattern. There is also evidence of pleural effusions, particularly on the left side, which appear as increased density in the lower lung fields. The heart size appears normal.\\n\\n**Conclusion:**\\n\\nThe findings are highly suggestive of COVID-19 pneumonia. The diffuse interstitial infiltrates and pleural effusions are characteristic of this viral infection.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['llm_analyze_image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/xray_medgemma.csv.{split}\")\n",
    "  \n",
    "    df_temp = pd.DataFrame(columns=['path_file_image', 'llm_analyze_image'])\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split},\", total=len(df)):\n",
    "        now_path = now_row.path_file_image\n",
    "        text = now_row.llm_analyze_image\n",
    "\n",
    "        section_pattern = r'(?:\\*\\*)?\\{?([A-Za-z ]+?)\\}?:?(?:\\*\\*)?\\n\\n|(?:\\.\\n\\n)?([A-Za-z ]+?):\\n\\n'\n",
    "        matches = list(re.finditer(section_pattern, text))\n",
    "        parsed = []\n",
    "\n",
    "        start = 0\n",
    "        for i, match in enumerate(matches):\n",
    "            title = match.group(1) or match.group(2)\n",
    "            title = title.strip()\n",
    "\n",
    "            content_start = match.end()\n",
    "            content_end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "            content = text[content_start:content_end].strip()\n",
    "\n",
    "            disclaimer = re.search(r'\\n\\n\\*?\\*?Disclaimer:.*', content, re.IGNORECASE | re.DOTALL)\n",
    "            if disclaimer:\n",
    "                content = content[:disclaimer.start()].strip()\n",
    "            parsed.append((title, content))\n",
    "        \n",
    "        extracted_data = \"\\n\\n\"\n",
    "        for idx, (title, content) in enumerate(parsed):\n",
    "            if idx == len(parsed) - 1:\n",
    "                extracted_data += f\"{content.replace('*   ', '')}\" + \" \\n\\n\"\n",
    "            else:\n",
    "                extracted_data += f\"* {title}\\n{content.replace('*   ', '    *   ')}\" + \" \\n\\n\"\n",
    "        \n",
    "        df_temp.loc[len(df_temp)] = [now_path, fix_broken_bullet_blocks(extracted_data)]\n",
    "    pd.DataFrame(df_temp).to_csv(f'datas/reasoning/xray/medgemma_xray_formatted.csv.{split}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train,: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35598/35598 [00:00<00:00, 113870.25it/s]\n",
      "Processing val,: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3758/3758 [00:00<00:00, 109188.99it/s]\n",
      "Processing test,: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5301/5301 [00:00<00:00, 119353.50it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "for split in ['train', 'val', 'test']:\n",
    "    df = pd.read_csv(f\"{DATA_PATH}/xray_medgemma.csv.{split}\")\n",
    "  \n",
    "    formatted_llm = []\n",
    "    for now_row in tqdm(df.itertuples(), desc=f\"Processing {split},\", total=len(df)):\n",
    "        text = now_row.llm_analyze_image\n",
    "        text = re.sub(r\"\\*\\*.*?\\*\\*\\n\\n\", \"\", str(text), flags=re.DOTALL)\n",
    "        text = re.sub(r\"\\n\\n.*?\\n\\n\", \"\", text, flags=re.DOTALL)\n",
    "        text = text.replace(\"\\n\", \" \").strip()\n",
    "        text = re.sub(r\"\\.\\s{2,}([A-Z])\", r\". \\1\", text)\n",
    "        text = re.sub(r\"\\*\\s{2,}\", \"\", text)\n",
    "        formatted_llm.append(text)\n",
    "    \n",
    "    df[\"formatted_llm_analyze_image\"] = formatted_llm\n",
    "    df.to_csv(f\"{DATA_PATH}/xray_medgemma.csv.{split}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b165c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "split = \"test\"\n",
    "df_reasoning = pd.read_csv(f\"{DATA_PATH}/xray_medgemma.csv.{split}\")\n",
    "df_original = pd.read_csv(f\"{DATA_PATH}/xray_metadata_llm.csv.{split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "696221aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>path_file</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9MYBHXF7M7CO</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZXP9O6G6H72N</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FYYUCI8WSKIA</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D9N0U52KL6A5</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J0L7VJ00EWJV</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>R2XWWTSNR8IA</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>W21VXDV1GVQR</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>ZSN3Z3H8C98M</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>0W4PAWWUMGDC</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>JR6YNBBNH00Y</td>\n",
       "      <td>/home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5301 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                                          path_file  disease\n",
       "0     9MYBHXF7M7CO  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        2\n",
       "1     ZXP9O6G6H72N  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        2\n",
       "2     FYYUCI8WSKIA  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        2\n",
       "3     D9N0U52KL6A5  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        2\n",
       "4     J0L7VJ00EWJV  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        2\n",
       "...            ...                                                ...      ...\n",
       "5296  R2XWWTSNR8IA  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        4\n",
       "5297  W21VXDV1GVQR  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        4\n",
       "5298  ZSN3Z3H8C98M  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        0\n",
       "5299  0W4PAWWUMGDC  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        4\n",
       "5300  JR6YNBBNH00Y  /home/is/dwipraseetyo-a/NAS_HAI/Datasets/combi...        4\n",
       "\n",
       "[5301 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c48847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>formatted_llm_analyze_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORU18QFQ7EFH</td>\n",
       "      <td>The chest X-ray demonstrates diffuse, bilatera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IX37B4ZUB1IQ</td>\n",
       "      <td>The chest X-ray shows diffuse, bilateral inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q6JS8BS4MRD9</td>\n",
       "      <td>The chest X-ray findings are suggestive of COV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>988GUD9IGCM1</td>\n",
       "      <td>The chest X-ray shows a relatively clear lung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2DK7ZQDS0M4I</td>\n",
       "      <td>The chest X-ray demonstrates diffuse, bilatera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35593</th>\n",
       "      <td>1GOVQY01H4M3</td>\n",
       "      <td>The chest X-ray findings are highly suggestive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35594</th>\n",
       "      <td>RZY9JRW4JK4R</td>\n",
       "      <td>The chest X-ray findings are highly suggestive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35595</th>\n",
       "      <td>BKZ6GYHYEV2Y</td>\n",
       "      <td>The chest X-ray findings are suggestive of Tub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35596</th>\n",
       "      <td>0BTN61W0Y4LY</td>\n",
       "      <td>The chest X-ray findings are highly suggestive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>ERSM47EVFOOD</td>\n",
       "      <td>The chest X-ray findings are highly suggestive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35598 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                        formatted_llm_analyze_image\n",
       "0      ORU18QFQ7EFH  The chest X-ray demonstrates diffuse, bilatera...\n",
       "1      IX37B4ZUB1IQ  The chest X-ray shows diffuse, bilateral inter...\n",
       "2      Q6JS8BS4MRD9  The chest X-ray findings are suggestive of COV...\n",
       "3      988GUD9IGCM1  The chest X-ray shows a relatively clear lung ...\n",
       "4      2DK7ZQDS0M4I  The chest X-ray demonstrates diffuse, bilatera...\n",
       "...             ...                                                ...\n",
       "35593  1GOVQY01H4M3  The chest X-ray findings are highly suggestive...\n",
       "35594  RZY9JRW4JK4R  The chest X-ray findings are highly suggestive...\n",
       "35595  BKZ6GYHYEV2Y  The chest X-ray findings are suggestive of Tub...\n",
       "35596  0BTN61W0Y4LY  The chest X-ray findings are highly suggestive...\n",
       "35597  ERSM47EVFOOD  The chest X-ray findings are highly suggestive...\n",
       "\n",
       "[35598 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reasoning.rename(columns={\"idx_col\": \"user_id\"})[[\"user_id\", \"formatted_llm_analyze_image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1600393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/is/dwipraseetyo-a/NAS_HAI/Datasets\"\n",
    "for split in ['train', 'val', 'test']:\n",
    "    df_reasoning = pd.read_csv(f\"{DATA_PATH}/xray_medgemma.csv.{split}\")\n",
    "    df_original = pd.read_csv(f\"{DATA_PATH}/xray_metadata_llm.csv.{split}\")\n",
    "    cols_to_drop = [\"llm_analyze_image_x\", \"llm_analyze_image_y\", \"llm_analyze_image\"]\n",
    "    df_original = df_original.drop(columns=[c for c in cols_to_drop if c in df_original.columns]) \n",
    "\n",
    "    df_joined = df_original.merge(\n",
    "        df_reasoning[[\"idx_col\", \"formatted_llm_analyze_image\"]].rename(columns={\"idx_col\": \"user_id\"}), \n",
    "        on=\"user_id\", \n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    df_joined.to_csv(f\"{DATA_PATH}/xray_metadata_llm_final.csv.{split}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
